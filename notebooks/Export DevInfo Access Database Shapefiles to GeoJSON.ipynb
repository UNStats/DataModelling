{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export DevInfo Access Database Shapefiles to GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DevInfo stores the three files (.shp, .shx, and .dbf) in 3 columns in the Access database. This script will execute a query that will return those files, plus an additional column, `Parent_NId`, that will be used to construct the file name for the output GeoJSON file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the needed python libraries\n",
    "Install the GDAL pythyon library (ogr import below) by opening the anaconda prompt and using `conda install gdal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from osgeo import ogr\n",
    "import pyodbc\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to see if you have the needed drivers installed to connect to an Access Database\n",
    "Run the line below and if you see an emtpy array: `[]` as a result, you may need to install the 64-bit ACE drivers\n",
    "\n",
    "*for reference https://github.com/mkleehammer/pyodbc/wiki/Connecting-to-Microsoft-Access*\n",
    "\n",
    "*for 64-bit drivers : https://www.microsoft.com/en-us/download/confirmation.aspx?id=13255*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in pyodbc.drivers() if x.startswith('Microsoft Access Driver')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_driver_lbl = 'Esri Shapefile'\n",
    "shp_driver = ogr.GetDriverByName(shp_driver_lbl)\n",
    "if shp_driver is None:\n",
    "    print ('{} driver not available.'.format(shp_driver_lbl))\n",
    "else:\n",
    "    print ('{} driver IS available.'.format(shp_driver_lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your working directory\n",
    "example: *C:\\users\\me\\working_directory\\my_country*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_working_directory = r'C:\\Users\\adam6475\\devinfo\\tanzania'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the path to your DevInfo Access Database\n",
    "example: *C:\\users\\me\\working_directory\\my_country\\my_devinfo_database.mdb (.accdb)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_database = r'C:\\Users\\adam6475\\devinfo\\tanzania\\TSED_20180423.mdb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the name of your output folder for the geojson files\n",
    "example: *C:\\users\\me\\working_directory\\my_country\\geojson*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gj_folder = r'C:\\Users\\adam6475\\devinfo\\tanzania\\geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the query against the DevInfo Access tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connStr = (\n",
    "    r'Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};'\n",
    "    r'DBQ={};'.format(access_database)\n",
    ")\n",
    "\n",
    "cnxn = pyodbc.connect(connStr)\n",
    "\n",
    "sql = \"\"\"\\\n",
    "SELECT \n",
    "UT_Area_Map_Layer.Layer_Shp AS SHP, \n",
    "UT_Area_Map_Layer.Layer_Shx AS SHX,\n",
    "UT_Area_Map_Layer.Layer_dbf AS DBF, \n",
    "UT_Area_Map_Layer.Layer_NId AS LAYER_NID, \n",
    "UT_Area_en.Area_NId AS AREA_NID, \n",
    "UT_Area_en.Area_ID AS AREA_ID, \n",
    "UT_Area_en.Area_Parent_NId AS PARENT_NID, \n",
    "UT_Area_en.Area_Name AS AREA_NAME, \n",
    "UT_Area_Level_en.Area_Level AS AREA_LEVEL, \n",
    "UT_Area_Level_en.Area_Level_Name AS AREA_LEVEL_NAME\n",
    "\n",
    "FROM \n",
    "UT_Area_Level_en INNER JOIN (UT_Area_Map_Layer INNER JOIN (UT_Area_en INNER JOIN UT_Area_Map ON UT_Area_en.Area_NId = UT_Area_Map.Area_NId) ON UT_Area_Map_Layer.Layer_NId = UT_Area_Map.Layer_NId) ON UT_Area_Level_en.Area_Level = UT_Area_en.Area_Level\n",
    "\n",
    "ORDER BY UT_Area_en.Area_Parent_NId  ASC\n",
    "\n",
    "\"\"\"\n",
    "crsr = cnxn.execute(sql)\n",
    "\n",
    "# export just a subset for testing\n",
    "# rows = crsr.fetchmany(5)\n",
    "\n",
    "# uncomment this to get crazy and export them all\n",
    "rows = crsr.fetchall()\n",
    "\n",
    "print ('sucessfully executed data query :: {} rows returned'.format(len(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group the result of the query by parent id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = {}\n",
    "for row in rows:\n",
    "    \n",
    "    parent_id = row.PARENT_NID\n",
    "    \n",
    "    if parent_id not in chunks:\n",
    "        chunks[parent_id] = {}\n",
    "        chunks[parent_id]['rows'] = []\n",
    "            \n",
    "    chunks[parent_id]['rows'].append(row)\n",
    "\n",
    "print ('done chunking data by parent')\n",
    "\n",
    "# uncomment to view the number of rows for each parent\n",
    "# for c in chunks:\n",
    "#     print (c, len(chunks[c]['rows']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each parent group, create a GeoJSON file with its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder_shp = os.path.abspath('{}/temp'.format(output_gj_folder))\n",
    "\n",
    "try:\n",
    "    os.mkdir(temp_folder_shp)\n",
    "except:\n",
    "    print ('unable to make temp shapes dir. may already exist')\n",
    "\n",
    "debug = []\n",
    "\n",
    "print ('exporting to geojson ...')\n",
    "\n",
    "for parent in chunks:\n",
    "    # test with just one parent\n",
    "#     if str(parent) != '86':\n",
    "#         continue\n",
    "        \n",
    "    msg = 'PARENT {}'.format(parent)\n",
    "#     print (msg)\n",
    "    debug.append(msg)\n",
    "    \n",
    "    feature_collection = {\n",
    "        'type' : 'FeatureCollection',\n",
    "        'features': []\n",
    "    }\n",
    "    \n",
    "    rows = chunks[parent]['rows']\n",
    "        \n",
    "    for i, row in enumerate(rows):\n",
    "        shp = row[0]\n",
    "        shx = row[1]\n",
    "        dbf = row[2]\n",
    "        \n",
    "        layer_id = row[3]\n",
    "        parent_id = row[6]\n",
    "        area_id = row[5]\n",
    "        area_name = row[7]\n",
    "        area_level = row[8]\n",
    "        \n",
    "        # get geometry\n",
    "        out_shp_path = os.path.abspath('{}/{}'.format(temp_folder_shp, area_id))\n",
    "        out_shp_path_ext = '{}.shp'.format(out_shp_path)\n",
    "            \n",
    "        with open('{}.shp'.format(out_shp_path), 'wb') as writer:\n",
    "            writer.write(shp)\n",
    "        with open('{}.shx'.format(out_shp_path), 'wb') as writer:\n",
    "            writer.write(shx)\n",
    "        with open('{}.dbf'.format(out_shp_path), 'wb') as writer:\n",
    "            writer.write(dbf)\n",
    "        # here we are also writing a GCS WGS 1984 .prj file that will define the spatial reference of each shapefile\n",
    "        with open('{}.prj'.format(out_shp_path), 'w') as writer:\n",
    "            writer.write('GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]]')\n",
    "        \n",
    "        # open the newly created area shapefile\n",
    "        area_shp_file = shp_driver.Open(out_shp_path_ext, 0)\n",
    "        area_layer = area_shp_file.GetLayer()\n",
    "        \n",
    "        feature_count = area_layer.GetFeatureCount()\n",
    "        \n",
    "        feature = None\n",
    "        if feature_count > 1:\n",
    "            where_clause = 'ID_ = \\'{}\\''.format(area_id)\n",
    "            area_layer.SetAttributeFilter(where_clause)\n",
    "            found_feature = area_layer.GetNextFeature()\n",
    "            if found_feature is None:\n",
    "                msg = 'unable to get feature with area_id :: {}'.format(area_id)\n",
    "#                 print (msg)\n",
    "                debug.append(msg)\n",
    "                continue\n",
    "            else:\n",
    "                feature = found_feature\n",
    "                            \n",
    "        else:\n",
    "            feature = area_layer.GetFeature(0)\n",
    "        \n",
    "        geom_ref = feature.GetGeometryRef()\n",
    "        geom_json_str = geom_ref.ExportToJson()\n",
    "        geom = json.loads(geom_json_str)\n",
    "        \n",
    "        # save and close the shapefile\n",
    "        area_shp_file = None\n",
    "\n",
    "        # setup the new feature\n",
    "        feature = {\n",
    "            'type': 'Feature',\n",
    "            'properties': {\n",
    "                'REF_AREA_ID': area_id,\n",
    "                'REF_AREA': area_name,\n",
    "                'LEVEL': area_level,\n",
    "                'PARENT_NID': parent,\n",
    "                'LAYER_NID': layer_id\n",
    "            },\n",
    "            'geometry': geom\n",
    "        }\n",
    "\n",
    "        feature_collection['features'].append(feature)\n",
    "    \n",
    "    out_parent_gj_filename = 'parent_{}.geojson'.format(str(parent))\n",
    "    out_parent_gj_path = os.path.abspath(os.path.join(output_gj_folder, out_parent_gj_filename))\n",
    "    \n",
    "    msg = 'writing {} features to {}'.format(len(feature_collection['features']), out_parent_gj_path)\n",
    "#     print (msg)\n",
    "    debug.append(msg)\n",
    "    \n",
    "    with open(out_parent_gj_path, 'w') as parent_gj_file:\n",
    "        parent_gj_file.write(json.dumps(feature_collection))     \n",
    "\n",
    "# delete the temp shapefile folders\n",
    "shutil.rmtree(temp_folder_shp, ignore_errors=True)\n",
    "\n",
    "print ('done')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view log results (optional)\n",
    "if you have the pandas library installed, [more info here](http://pandas.pydata.org/pandas-docs/stable/install.html), you can view the results in a table here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "\n",
    "df = pd.DataFrame(debug, columns=['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'testing/log.csv'\n",
    "df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
